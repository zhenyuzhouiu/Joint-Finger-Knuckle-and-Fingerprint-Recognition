\section{Template Generation and Matching\label{template-generation}}

\subsection{Finger Knuckle Template Generation\label{fk-template}}

\begin{figure*}
    \centering
    \includegraphics[width=6.5in]{Figures/framework/ST-Residual/Framework.png}
    \caption{We have proposal a new finger knuckle recognition framework with quadruplet architecture. \textbf{1.} Quadruplet: We trained our model with the quadruplet architecture \cite{chen2017beyond} for decreasing inter-class variance and increasing intra-class variance. \textbf{2.} STResNet: The new architecture is a fully connected convolution network. If the input data size is a tensor $[3, H, W]$, the network will output feature maps of $[64, H/4, W/4]$ size. \textbf{3.} ST-Residual: This module consists of a STN \cite{jaderberg2015spatial} module, two convolution layers, and an SE \cite{hu2018squeeze} module combined to from a residual module.
     \textbf{4.} RS-SSIM: Meanwhile, we introduce a new loss function based on the SSIM index for enhance the STResNet model rotation and translation invariance ability by rotating and shifting output feature maps.}
    \label{framework}
\end{figure*}

Each of the segmented and normalized finger-knuckle images are subjected to the feature extraction to generate respective templates for the matching. There are a range of spatial domain \cite{sricharan2006knuckle}, \cite{kumar2009personal}, \cite{zhang2010online}, \cite{zhu2010multimodal}, \cite{zheng20163d}, \cite{kumar2016personal} and spectral domain \cite{aoyama2011finger}, \cite{kumar2015recovering} methods investigated in the literature to match finger knuckle patterns. Among these methods spatial-domain methods are quite attractive as they are computationally simpler and have shown to offer state-of-the-art results. \sout{We employed the local feature descriptor based approach introduced in \cite{zheng20163d}, \cite{kumar2016personal} to generate finger knuckle templates as this approach is computationally attractive, accurate and generates smallest finger-knuckle templates (one-bit-per-pixel) that can be more conveniently stored along with the fingerprint-templates for the real applications.} \textcolor{red}{In this same domain, convolution networks can also learn very stable feature information due to convolution kernel. For example, the RFN \cite{liu2020contactless} achieves significant performance in the palmprint recognition task and the FKNet \cite{cheng2020deep} in the 3D finger knuckle recognition task.}

\textcolor{red}{Especially for the normal convolution operator on CNN model, it uses sliding window methods to convolve the kernel and images, and update the kernel by backpropagation to learn the robust features. But the normal convolution cannot get the rich rotation and translation features which will limit the performance of CNN. Meanwhile when user put their hand on our finger knuckle assisted fingerprint system under the real world application scenario, their finger, with 6 DOF, are prone bending as well as rotating rather than straightening, which leads to deformable finger knuckle crease information. It is a critical problem that will lead to a degradation of the performance a lot of template generation methods. For solving the deformable feature problem, the spatial transformer network (STN) \cite{jaderberg2015spatial} can learn the 2D affine transformation matrix to affine the whole feature maps or images to solving the deformable problem. And the deformable convolution network \cite{zhu2019deformable} using a deformable convolution to enhance the CNN transformation ability, but it updates the sampling position and sample weight of a local kernel which more fit on local deformation problem. We can also use the data augmentation methods to rotate, translate, and scale the input images to enhance the generalization ability of model on deformable dataset.}

\textcolor{red}{\subsubsection{STResNet} When the palm of the hand is under the shooting environment of our system, we need to place the hand flat on the platform, which leads to the finger knuckle being more prone to overall affine transformation rather than local deformations. Therefore, we introduce a new module, called ST-Residual on Fig. \ref{framework}, based on the STN model, residual network \cite{he2016deep}, and SE \cite{hu2018squeeze}. We first use an STN module to affine the intermediate features to increase the transformation information, and then connect two convolutional layers to enhance the feature extraction. Since the learned channel information is not equally important, an SE module is used to learn the channel importance. Finally, a residual module is formed to fuse the learned deformable features with the original features. With our proposal new ST-Residual block, we compose a new network called STResNet, as shown on the Fig. \ref{framework}. Firstly, we use three normal fully connected convolution layers and a normal residual block to get the crease information of input finger knuckle with $[3, H, W]$. Then it connects three ST-Residual block to get deformable features for increasing the deformable ability. Finally, use a normal convolution layers to get the final features with $[64, H/4, W/4]$}


\textcolor{red}{\subsubsection{RS-SSIM} After extracting the feature maps, we can use MSE, PSNR and SSIM \cite{wang2004image} to calculate the similarity score between two feature maps. As for the MSE and PSNR, they calculate the absolute difference between two images. However, SSIM \cite{wang2004image} can get the structural similarity which is very robust when compare two texture feature maps. It can use sliding window approach to get the local matching score and get the mean value of all local matching score between two images, which is very fit on matching two texture feature maps. We also proposal a new loss based on the SSIM, called RS-SSIM in the Fig. \ref{framework}, and it can rotate and shift feature maps in a \textit{predefined} range $\theta_1 \leq \theta \leq \theta_2$ by grid generator and sampler followed the reference \cite{jaderberg2015spatial} for getting more robust similarity scores which can reduce the inter-class variance. As for the parameter $\theta$, it is a $2 \times 3$ 2D affine transformation matrix. Among these rotated and shifted templates, we will get the minimal value $SSIM_i$ between the $F_i^1$ and the $F^2$, then the backpropagation will along the $F_i^1$ and $F^2$ path to update the model learnable weights. In order to enable the whole network STResNet to update the weights in training process, we implement a differentiable SSIM so that the network can be trained smoothly. It is worth noting that in practice, it is very time consuming to affine transformation with iteration. Therefore we firstly form a certain range of transformation matrix ($\theta_1 \leq \theta \leq \theta_2$), and then perform the batch operation to speed up.}

\textcolor{red}{We trained our proposal framework with the quadruplet architecture \cite{chen2017beyond} on the segmented middle finger knuckle of left hand. It is worthy to note that how to choose the quadruplet when we train our model. Each subject offers five samples, so that for the positive ($I_p$), we choose the one with the largest SSIM distance with the anchor ($I_a$) among the remaining four samples in the same subject data. We arbitrarily choose two other different subjects, and tow with the smallest gap with the anchor ($I_a$) as negative1 ($I_{n1}$) and negative2 ($I_{n2}$). We have presented our experiment results in the Section \ref{fk-performance}, and compare to the state-of-the-art finger knuckle recognition model on the Section \ref{discussion}.}


\subsection{Fingerprint Template Generation\label{fp-template}}

Among a range of methods introduced in the literature \cite{maltoni2009handbook} to match fingerprint images, minutiae-based methods are widely employed and therefore preferred. We considered a range of popular methods and implementations available in the references to generate fingerprint templates. Among various fingerprint matchers employed in the literature, NBIS (NIST Biometric Image Software) \cite{cappelli2010minutia} and minutiae cylinder code (MCC) \cite{watson2007user} are quite popular. We also considered a commercial off-the-shelf (COTS) matcher \cite{verifinger} which has shown quite accurate results in many references. Simultaneously acquired fingerprint images from the slap-fingerprint sensors are automatically segmented and employed to generate fingerprint templates. These templates are used to generate respective match scores that are consolidated for the user authentication. 

\subsection{Dynamic Score Consolidation\label{dynamic-score}}

The match scores generated from two independent pieces of evidences are consolidated to achieve a more reliable decision score for the user authentication. Biometrics literature \cite{maltoni2009handbook} provides extensive investigation on a range of methods to consolidate decisions from two pieces of evidences or features. Such consolidation from can be achieved at feature level, score level, or at the decision level. The score level combination is most widely used in the literature and is widely adapted \cite{jain2012biometric} in a range of biometrics system, largely due to its simplicity and the performance. The objective of our system is to serve as an add-on system on the top of existing or deployed slap-fingerprint system where the match scores are inherently available from the respective minutiae templates. Therefore, score level combination was preferred and adapted for the score consolidation in our system.  
\begin{algorithm}[h!]
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \caption{Dynamic Match Score Consolidation}
    \begin{algorithmic}[1]
        \REQUIRE Match score $\bm{s_k, s_f, q_k, q_f}$ \\ 
        \ENSURE Consolidation score $\bm{s_c}$;\\
        \IF {$q_k = 0 $ and $0 < q_f \leq 1$}
            \STATE $s_c = s_f$
        \ENDIF
        \IF {$ 0 < q_k \leq 1$ and $q_f = 0$}
            \STATE $s_c = s_k$
        \ENDIF
        \IF {$q_k = 0$ and $q_f = 0$}
            \STATE $s_c = 0$
        \ELSE
            \STATE $s_c = w \times s_k + (1-w)*s_f$
        \ENDIF
        \RETURN $s_c$
    \end{algorithmic}
    \label{algorithm-2}
\end{algorithm}

Real biometric systems during their deployments are often presented with missing or degraded quality of biometric samples and therefore the score-level consolidation scheme should be adaptive to such inputs. Therefore, we developed a dynamic scheme to consolidate match scores from two simultaneously generated match scores from the fingerprint and the finger knuckle. Let the match score from fingerprint be represented by $s_f$ and the match score from the finger knuckle be represented by $s_k$. The confidence or the quality of input biometric image sample, as shown in Fig. \ref{block-diagram}, can be denoted as $q_k$ and $q_f$ respectively for the finger knuckle and fingerprint. \textcolor{red}{If we can not detect or segment the finger knuckle or fingerprint, we use the score 0 to represent it.} The consolidated match score $s_c$ is generated as shown in Algorithm \ref{algorithm-2}. The weight $w ( 0 \leq w \leq 1)$  represents weight and is fixed empirically for all the experimental results in this paper. This scheme ensures that in case of missing or low quality biometric images, the importance is automatically granted for the other biometric modality.  

